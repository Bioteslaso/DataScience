{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6462427d-f93a-46a3-aef1-f16e7a7f7bbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Questions on Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584e7087-3555-4536-b621-0515ed07b2cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cd8e3c-8e2f-465d-b1f3-6d6bd466def0",
   "metadata": {},
   "source": [
    "Assume that we have decided to use k-means clustering. \n",
    "\n",
    "What of the following statements are correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f08207-06e2-4dbf-aa35-3845df086260",
   "metadata": {},
   "source": [
    "A: The algorithm will terminate when two consecutive runs, using different random initializations, result in the same clusters\n",
    "\n",
    "B: Missing values do not have to be preprocessed  \n",
    "\n",
    "C: Min-max normalization will not affect the result when using Hamming distance\n",
    "\n",
    "D: None of the output clusters can be singletons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b638440a-1c5f-4ef8-a5c0-8e6b6605e12f",
   "metadata": {},
   "source": [
    "Correct answer: C \n",
    "\n",
    "Explanation: \n",
    "The algorithm will not (by itself) rerun with different initializations.\n",
    "\n",
    "Missing values need to be handled in order to allow for distance calculations. \n",
    "\n",
    "Hamming distance considers equality/inequality only, which is not affected by min-max normalization.\n",
    "\n",
    "Nothing prevents the algorithm from producing singleton clusters; instances in singleton clusters will not be moved and it may be that no other instances are closer to a singleton than to the current cluster center."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bae2a4c-6ba4-49a4-8d3a-f4df12fc9564",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3f48a8-8400-48e8-ba46-5c27b1fd238d",
   "metadata": {},
   "source": [
    "Assume that we have decided to use k-means clustering. \n",
    "\n",
    "What of the following statements concerning cluster evaluation metrics are correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a78170c-0c4b-4b01-a99f-2cc735e9b6d7",
   "metadata": {},
   "source": [
    "A: Post-processing the output by merging clusters could reduce the sum-of-squared-errors\n",
    "\n",
    "B: If the distance between all pairs of instances are positive, then the Silhouette value for an instance assigned to a singleton cluster is always 1\n",
    "\n",
    "C: If an instance with a negative Silhouette value is moved to the nearest other cluster, then the Silhouette value of the instance will increase\n",
    "\n",
    "D: If an original set of instances is used to generate two equal-sized clusters, then the Rand index, when comparing the two clusters to the original single cluster, is 0.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82ed6f7-ee65-4046-8774-94206623c3aa",
   "metadata": {},
   "source": [
    "Correct answers: B, C, D\n",
    "\n",
    "Explanation: \n",
    "\n",
    "The sum-of-squared-errors are calculated with respect to the cluster centers (centroids) and the errors in the original clusters can only increase if the centroids move, which will be the case when merging two clusters.\n",
    "\n",
    "The average distance from the instance in the singleton cluster to instances in the own cluster will be zero, i.e., a(o) = 0, while it will be positive for the nearest other cluster, i.e., b(o) > 0. Hence, the Silhouette value will be b(o)/b(o) = 1.\n",
    "\n",
    "The Silhouette value is negative for an instance if a(o) > b(o); by reassigning the instance to the other cluster then the Silhouette value will become positive, since there is no other cluster for which the average distances are lower.\n",
    "\n",
    "For each pair of instances that appear in the same of the two clusters, they will also appear in the same (original) cluster. For each pair of instances that do not appear in the same of the two clusters, they will not appear in different clusters in the (original) clustering. This means that of all pairs, half of them will be \"correctly\" clustered according to the Rand index. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e9c92f-2963-4d4a-9963-77d1374db45d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9321fae4-5d2b-430f-a595-a31c713575bd",
   "metadata": {},
   "source": [
    "What are well-founded reasons for choosing to use agglomerative clustering instead of k-means clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836211dc-3109-475a-a57d-6441c1db7357",
   "metadata": {},
   "source": [
    "A: Agglomerative clustering is deterministic\n",
    "\n",
    "B: Agglomerative clustering does not require the number of clusters to be provided\n",
    "\n",
    "C: The output shows how any pair of instances ends up in the same cluster  \n",
    "\n",
    "D: Agglomerative clustering is faster when assigning a cluster to a test object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981d28db-ee33-4837-a2dd-e9e37500b6a7",
   "metadata": {},
   "source": [
    "Correct answers: A, B, C\n",
    "\n",
    "Explanation: \n",
    "\n",
    "Agglomerative clustering always produce the same output, unless ties regarding what clusters to merge are handled randomly.\n",
    "\n",
    "Agglomerative clustering continues to merge a pair of clusters until all have been merged; there is no need to specify a number of clusters.\n",
    "\n",
    "The hierarchical structure shows how clusters have been merged, starting with the singleton clusters in the original dataset.\n",
    "\n",
    "K-means requires only that the distance to the k centroids are calculated, while the number of clusters produced by agglomerative clustering to be evaluated are typically much larger. Even if we restrict the number of clusters to be the same for both techniques, the linkage is often more costly to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4425cb-3c3f-4cc7-a223-e54b1b2e4c6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5320dddc-2b05-45dc-b276-2d4eb6d1e8b3",
   "metadata": {},
   "source": [
    "Assume that we would like to use agglomerative clustering. \n",
    "\n",
    "What of the statements are correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42368a0b-a111-4436-94f9-163d4bd8a2ee",
   "metadata": {},
   "source": [
    "A: The algorithm is fully deterministic when there are no ties regarding what clusters to merge \n",
    "\n",
    "B: When there are ties, resolving them randomly does not have any effect on the result, independently of what merging criterion is used \n",
    "\n",
    "C: For single-linkage, resolving ties randomly does not have any effect on the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d378aeb-5462-4a5d-9609-401859d04d6a",
   "metadata": {},
   "source": [
    "Correct answer: A, C\n",
    "\n",
    "Explanation: Ties appear when performing agglomerative (bottom-up) clustering when two\n",
    "or more alternatives of clusters to merge result in the same score. In general,\n",
    "resolving such ties randomly, i.e., picking any of the alternatives arbitrarily\n",
    "with some element of chance, could result in completely different clusterings,\n",
    "and would hence motivate multiple re-runs, similar to what is recommended\n",
    "for k-means clustering. (If no such ties occur, then there is no point to re-run\n",
    "agglomerative clustering, as it becomes completely deterministic, which is also\n",
    "the case if we choose to handle ties in a non-stochastic way). When single-\n",
    "linkage is used, the score is the smallest distance between a pair of elements in\n",
    "two different clusters. This means that in case of ties between several alternative\n",
    "clusters to merge, these will by necessity be merged in sequence; the merging\n",
    "of two clusters cannot result in that the smallest distance between any pair of\n",
    "clusters becomes smaller than for the tied clusters. Since the clusters are merged\n",
    "in sequence, the exact order in which this is done has no effect on sub-sequent\n",
    "mergings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eb1e1e-1d13-49dd-9d49-04bcc9cda484",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734c5e23-eba5-4164-a16d-327b25428218",
   "metadata": {},
   "source": [
    "Assume that we are given two association rules R1 = A → C and R2 = B → C, where A, B and C are itemsets.\n",
    "\n",
    "What of the following statements are correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d0059e-9b17-4137-9801-0019323e5206",
   "metadata": {},
   "source": [
    "A: If A $\\subset$ B, then A has a higher support than B\n",
    "\n",
    "B: If A $\\subset$ B, then R1 cannot have a higher confidence than R2\n",
    "\n",
    "C: If C is a class label and R1 has a higher confidence than R2, then we can expect R1 to have a higher precision for class C than R2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa07b54-d223-4f94-9d83-41bd8b2c59b4",
   "metadata": {},
   "source": [
    "Correct answer: None\n",
    "\n",
    "Explanation: Assume that B contains one additional item compared to A, and that this item always occurs together with an item in A in the database; then A and B will have the same support, while A is a subset of B.\n",
    "\n",
    "Assume the following itemsets (D):\n",
    "{a, b}\n",
    "{a, b, c}\n",
    "{a, c}\n",
    "{a, c, d} \n",
    "\n",
    "Let R1 = {a} → {c} : the confidence is then cov({a, c},D)/cov({a},D) = 3/4\n",
    "\n",
    "Let R2 = {a, b} → {c} : the confidence is then cov({a, b, c},D)/cov({a, b},D) = 1/2\n",
    "\n",
    "A rule with a high confidence may have a very low support, and hence may have a low precision when applied to independent test instances (not included in\n",
    "the database from which the rules were generated). For example, a rule with\n",
    "a confidence of 100% may have a support of only one instance, and hence the\n",
    "conclusion may only hold in 50% of the test cases, while a rule with slightly\n",
    "lower confidence, but much higher support, can be expected to be more correct\n",
    "on independent test instances. Hence, confidence alone (without a sufficiently\n",
    "high support) is not necessarily a meaningful evaluation criterion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be792f6-a9d6-4063-bbf6-61647dd87b13",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a54658-47b3-4723-a9ac-b6cd5211e8c1",
   "metadata": {},
   "source": [
    "Assume that we have generated a set of association rules with a specified support\n",
    "and confidence, from a dataset with a set of binary features and binary class\n",
    "labels, encoded as itemsets. Assume that we have selected a subset of the rules,\n",
    "for which the heads (consequents) contain only a class label and that we want to use\n",
    "this subset of rules to classify a novel test instance, i.e., to assign one of the two\n",
    "class labels.\n",
    "\n",
    "What of the following are correct?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fb13d1-5ce4-43be-83bf-528a326d3ca1",
   "metadata": {},
   "source": [
    "A: It may be that multiple rules with a confidence = 1 are applicable, i.e., the conditions (antecedents) are subsets of the itemset representing the instance to be classified, but with different consequents; this means that rules with maximum confidence are in conflict regarding what class label to assign\n",
    "\n",
    "B: It may be that for some test instance, there is no rule such that the condition\n",
    "(antecedent) is a subset of the itemset representing the instance to be classified;\n",
    "this means that there is no applicable rule that can suggest what class label to\n",
    "assign.\n",
    "\n",
    "C: If we increase the minimum support, we should expect more rules to be applicable\n",
    "\n",
    "D: If we decrease the minimum confidence, we should expect more rules to be applicable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eca79a-5691-4536-a74c-5380eeb58946",
   "metadata": {},
   "source": [
    "Correct answer: A, B, D\n",
    "\n",
    "Explanation: \n",
    "\n",
    "It could very well be that rules with perfect confidence (= 1) have logically overlapping (non-exclusive) antecedents, but for which there is no overlap in the given database. They could hence  \n",
    "cover a test instance and predict different class labels.\n",
    "\n",
    "There is no guarantee that the generated rules cover all possible combinations of itemsets; in the extreme case, there are no rules that meet the confidence and support requirements.\n",
    "\n",
    "Increasing minimum support means that fewer frequent itemsets are found, and hence there will be fewer potential candidate itemsets to form rules from. If we instead decrease the confidence threshold, the number of generated rules can be expected to increase, and hence also the number of applicable rules.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
